{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport argparse\nimport math\nimport torch\nimport sys\nimport time\nimport datetime\nfrom sklearn.metrics import average_precision_score,roc_auc_score, classification_report\nfrom __future__ import print_function\nimport torch.optim as optim\nimport os\nfrom sklearn.metrics import roc_auc_score, f1_score\nimport torch.backends.cudnn as cudnn\nfrom torchvision import transforms, datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport torchvision\nimport torch.utils.data as data\nfrom PIL import Image\nimport sys\nfrom sklearn.metrics import precision_score,recall_score\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom scipy.sparse import csr_matrix","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.02368,"end_time":"2023-08-24T16:44:05.741240","exception":false,"start_time":"2023-08-24T16:44:05.717560","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-03T07:28:52.261822Z","iopub.execute_input":"2023-09-03T07:28:52.262218Z","iopub.status.idle":"2023-09-03T07:28:52.270742Z","shell.execute_reply.started":"2023-09-03T07:28:52.262185Z","shell.execute_reply":"2023-09-03T07:28:52.269825Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# *   **Arguments**","metadata":{}},{"cell_type":"code","source":"### from config.config_linear import parse_option ###\n\n\ndef parse_option(args):\n    parser = argparse.ArgumentParser('argument for training')\n\n    parser.add_argument('--print_freq', type=int, default=10,\n                        help='print frequency')\n    parser.add_argument('--save_freq', type=int, default=50,\n                        help='save frequency')\n    parser.add_argument('--batch_size', type=int, default=128,\n                        help='batch_size')\n    parser.add_argument('--num_workers', type=int, default=2,\n                        help='num of workers to use')\n    parser.add_argument('--epochs', type=int, default=25,\n                        help='number of training epochs')\n    parser.add_argument('--n_cls', type=int, default=2,\n                        help='number of training epochs')\n    parser.add_argument('--super', type=int, default=0,\n                        help='number of training epochs')\n    parser.add_argument('--type', type=int, default=0,\n                        help='number of training epochs')\n    parser.add_argument('--biomarker', type=str, default='fluid_irf')\n    # optimization\n    parser.add_argument('--learning_rate', type=float, default=0.05,\n                        help='learning rate')\n    parser.add_argument('--patient_lambda', type=float, default=1,\n                        help='learning rate')\n    parser.add_argument('--lr_decay_epochs', type=str, default='100',\n                        help='where to decay lr, can be a list')\n    parser.add_argument('--lr_decay_rate', type=float, default=0.1,\n                        help='decay rate for learning rate')\n    parser.add_argument('--weight_decay', type=float, default=0,\n                        help='weight decay')\n    parser.add_argument('--momentum', type=float, default=0.9,\n                        help='momentum')\n    parser.add_argument('--device', type=str, default='cuda:0')\n    parser.add_argument('--parallel', type=int, default=1, help='data parallel')\n    # model dataset\n    parser.add_argument('--model', type=str, default='resnet50')\n    parser.add_argument('--train_csv_path', type=str, default='train data csv')\n    parser.add_argument('--test_csv_path', type=str, default='test data csv')\n    parser.add_argument('--train_image_path', type=str, default='/data/Datasets')\n    parser.add_argument('--test_image_path', type=str, default='/data/Datasets')\n    parser.add_argument('--val_csv_path', type=str, default='val data csv')\n    parser.add_argument('--val_image_path', type=str, default='val data image')\n    parser.add_argument('--results_dir_contrastive', type=str, default='/home/kiran/Desktop/Dev/SupCon_OCT_Clinical/results.txt')\n    parser.add_argument('--img_dir', type=str, default='image directory')\n    parser.add_argument('--model_type', type=str, default='bcva')\n    parser.add_argument('--multi', type=int, default=0)\n    parser.add_argument('--noise_analysis', type=int, default=0)\n    parser.add_argument('--severity_analysis', type=int, default=0)\n    parser.add_argument('--dataset', type=str, default='Prime',\n                        choices=['OCT','Biomarker','Prime'], help='dataset')\n\n    # other setting\n    parser.add_argument('--cosine', action='store_true',\n                        help='using cosine annealing')\n    parser.add_argument('--warm', action='store_true',\n                        help='warm-up for large batch training')\n    parser.add_argument('--ford_region',type = int,default = 0,\n                        help='Training on 6 region classes or not')\n    parser.add_argument('--percentage', type=int, default=100,\n                        help='Percentage of Biomarker Training Data Utilized')\n\n    parser.add_argument('--ckpt', type=str, default='',\n                        help='path to pre-trained model')\n    parser.add_argument('--backbone_training', type=str, default='BCVA',\n                        help='manner in which backbone was trained')\n    parser.add_argument('--patient_split', type=int, default=1,\n                        help='choose method')\n    opt = parser.parse_args(args)\n\n    # set the path according to the environment\n    opt.data_folder = './datasets/'\n\n    iterations = opt.lr_decay_epochs.split(',')\n    opt.lr_decay_epochs = list([])\n    for it in iterations:\n        opt.lr_decay_epochs.append(int(it))\n\n    opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n        format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n               opt.batch_size)\n\n    if opt.cosine:\n        opt.model_name = '{}_cosine'.format(opt.model_name)\n\n    # warm-up for large-batch training,\n    if opt.warm:\n        opt.model_name = '{}_warm'.format(opt.model_name)\n        opt.warmup_from = 0.01\n        opt.warm_epochs = 10\n        if opt.cosine:\n            eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n            opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n                    1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n        else:\n            opt.warmup_to = opt.learning_rate\n\n    if opt.dataset == 'cifar10':\n        opt.n_cls = 10\n    elif opt.dataset == 'cifar100':\n        opt.n_cls = 100\n    elif opt.dataset == 'Ford':\n        opt.n_cls = 3\n    elif opt.dataset == 'Ford_Region':\n        opt.n_cls = 3\n    elif opt.dataset == 'covid_kaggle':\n        opt.n_cls = 4\n    elif opt.dataset == 'qu_dataset':\n        opt.n_cls = 3\n    elif opt.dataset == 'covid_x':\n        opt.n_cls = 2\n    elif opt.dataset == 'covid_x_A':\n        opt.n_cls = 3\n    elif opt.dataset == 'OCT':\n        opt.n_cls = 4\n    elif opt.dataset == 'Prime':\n        opt.n_cls = 2\n    else:\n        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n\n    return opt","metadata":{"papermill":{"duration":0.034306,"end_time":"2023-08-24T16:44:05.781944","exception":false,"start_time":"2023-08-24T16:44:05.747638","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-03T07:28:52.279543Z","iopub.execute_input":"2023-09-03T07:28:52.280149Z","iopub.status.idle":"2023-09-03T07:28:52.305346Z","shell.execute_reply.started":"2023-09-03T07:28:52.280117Z","shell.execute_reply":"2023-09-03T07:28:52.304182Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"* # Training Main","metadata":{}},{"cell_type":"code","source":"def main():\n    best_acc = 0\n    opt = parse_option(args)\n\n    # build data loader\n    device = opt.device\n    train_loader,  test_loader = set_loader_new(opt)\n\n    acc_list = []\n    prec_list = []\n    rec_list = []\n    spec_list = []\n    # training routine\n    for i in range(0,1):\n        r_list = []\n        model, classifier, criterion = set_model(opt)\n        optimizer = set_optimizer(opt, classifier)\n        \n        for epoch in range(1, opt.epochs + 1):\n            adjust_learning_rate(opt, optimizer, epoch)\n\n            # train for one epoch\n            time1 = time.time()\n            loss, acc = train_OCT(train_loader, model, classifier, criterion,\n                              optimizer, epoch, opt)\n            time2 = time.time()\n#             print('Train epoch {}, total time {:.2f}, accuracy:{:.2f}'.format(\n#                 epoch, time2 - time1, acc))\n\n            loss, test_acc,prec,rec,spec, r = validate(test_loader, model, classifier, criterion, opt)\n            print('Train epoch {}, total time {:.2f}, accuracy:{:.2f}, f1_score:{:.2f}'.format(epoch, time2 - time1, acc, r))\n            \n            r_list.append(r)\n        \n        print(r_list)\n        \n        acc_list.append(acc)\n        prec_list.append(prec)\n        rec_list.append(rec)\n        spec_list.append(spec)\n    df = pd.DataFrame({'Accuracy':acc_list,'Precision':prec_list,'Recall':rec_list,'Specificity':spec_list})\n    excel_name = opt.backbone_training + '_' + opt.biomarker + '_' + str(opt.patient_split) + '.csv'\n    df.to_csv(excel_name, index=False)\n\ndef train_OCT(train_loader, model, classifier, criterion, optimizer, epoch, opt):\n    \"\"\"one epoch training\"\"\"\n    model.eval()\n    classifier.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    device = opt.device\n    end = time.time()\n    for idx, (image, vit_deb,ir_hrf, full_vit,partial_vit,fluid_irf,drt,eye_id,bcva,cst,patient) in enumerate(train_loader):\n        data_time.update(time.time() - end)\n\n        images = image.to(device)\n\n        if (opt.biomarker == 'vit_deb'):\n            labels = vit_deb\n        elif (opt.biomarker == 'ir_hrf'):\n            labels = ir_hrf\n        elif (opt.biomarker == 'full_vit'):\n            labels = full_vit\n        elif (opt.biomarker == 'partial_vit'):\n            labels = partial_vit\n        elif (opt.biomarker == 'drt'):\n            labels = drt\n        else:\n            labels = fluid_irf\n            \n#         labels = labels.long()\n#         labels = torch.tensor([labels])\n        labels = labels.float()\n        bsz = labels.shape[0]\n        labels=labels.to(device)\n        \n        # warm-up learning rate\n        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n\n        # compute loss\n        with torch.no_grad():\n            features = model.encoder(images)\n\n        output = classifier(features.detach())\n   #     probabilities = torch.sigmoid(output)\n        \n#         output = output.squeeze()\n   #     print(\"output\",output.shape,\"labels\",labels.shape)\n    #    print(\"Outputs =\",probabilities)\n     #   print(\"Labels =\",labels)\n\n        loss = criterion(output, labels)\n\n        # update metric\n        losses.update(loss.item(), bsz)\n\n        acc1= accuracy_single(output, labels, topk=(1,))\n\n\n        top1.update(acc1[0].item(), bsz)\n\n        # SGD\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # print info\n        if (idx + 1) % opt.print_freq == 0:\n            print('Train: [{0}][{1}/{2}]\\t'\n                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n                  'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n                  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n                   epoch, idx + 1, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1))\n            sys.stdout.flush()\n\n    return losses.avg, top1.avg\n\n\ndef validate(val_loader, model, classifier, criterion, opt):\n    \"\"\"validation\"\"\"\n    model.eval()\n    classifier.eval()\n    device = opt.device\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    label_list = []\n    out_list = []\n    with torch.no_grad():\n        end = time.time()\n        for idx, (image, vit_deb,ir_hrf, full_vit,partial_vit,fluid_irf,drt) in enumerate(val_loader):\n            images = image.float().to(device)\n\n            if (opt.biomarker == 'vit_deb'):\n                labels = vit_deb\n            elif (opt.biomarker == 'ir_hrf'):\n                labels = ir_hrf\n            elif (opt.biomarker == 'full_vit'):\n                labels = full_vit\n            elif (opt.biomarker == 'partial_vit'):\n                labels = partial_vit\n            elif (opt.biomarker == 'drt'):\n                labels = drt\n            else:\n                labels = fluid_irf\n                \n#             labels = torch.tensor([labels])\n#             labels = labels.long()\n            labels = labels.float()\n            label_list.append(labels.detach().cpu().numpy())\n            labels = labels.to(device)\n            bsz = labels.shape[0]\n\n            # forward\n            output = classifier(model.encoder(images))\n#             output = output.squeeze()\n\n            loss = criterion(output, labels)\n            _, pred = output.topk(1, 1, True, True)\n            output = torch.round(torch.sigmoid(output))\n\n            out_list.append(output.detach().cpu().numpy())\n            # update metri  c\n            losses.update(loss.item(), bsz)\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n#             if idx % opt.print_freq == 0:\n#                 print('Test: [{0}/{1}]\\t'\n#                       'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n#                       'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n#                       'Acc@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n#                        idx, len(val_loader), batch_time=batch_time,\n#                        loss=losses, top1=top1))\n\n    label_list = np.squeeze(label_list, axis=(2,))\n    label_array = np.array(label_list)\n\n    out_array = np.array(out_list)\n    out_array = np.concatenate(out_list, axis=0)\n    print(\"output\",out_array[0:10])\n    print(\"labels\",label_array[0:10])\n    \n    r = f1_score(label_array.flatten(), out_array.flatten(), average='macro')\n    #     r = f1_score(label_array, out_array, average='macro')\n    \n    prec = precision_score(label_array.flatten(), out_array.flatten())\n    rec = recall_score(label_array.flatten(), out_array.flatten())\n    spec = recall_score(label_array.flatten(), out_array.flatten(), pos_label=0)\n\n    return losses.avg, top1.avg,prec, rec, spec, r","metadata":{"execution":{"iopub.status.busy":"2023-09-03T07:28:52.418501Z","iopub.execute_input":"2023-09-03T07:28:52.418778Z","iopub.status.idle":"2023-09-03T07:28:52.450659Z","shell.execute_reply.started":"2023-09-03T07:28:52.418755Z","shell.execute_reply":"2023-09-03T07:28:52.449678Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# *   **Training Multi**","metadata":{}},{"cell_type":"code","source":"### from training_linear.training_one_epoch_ckpt_multi import main_multilabel ###\n### main_multilabel ###\n\n\ndef train_OCT_multilabel(train_loader, model, classifier, criterion, optimizer, epoch, opt):\n    \"\"\"one epoch training\"\"\"\n    model.eval()\n    classifier.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    device = opt.device\n    end = time.time()\n    \n#     for idx, (image, bio_tensor,eye_id,bcva,cst,patient) in enumerate(train_loader):\n    for idx, (image, bio_tensor) in enumerate(train_loader):\n        data_time.update(time.time() - end)\n\n        images = image.to(device)\n\n        labels = bio_tensor\n        labels = labels.float()\n        bsz = labels.shape[0]\n        labels=labels.to(device)\n        \n        # warm-up learning rate\n        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n\n        # compute loss\n        with torch.no_grad():\n            features = model.encoder(images)\n\n        output = classifier(features.detach())\n#         print(\"Outputs =\",output)\n#         print(\"Labels =\",labels)\n        \n        loss = criterion(output, labels)\n\n        # update metric\n        losses.update(loss.item(), bsz)\n        acc1= accuracy(output, labels, topk=(1,))\n        top1.update(acc1[0].item(), bsz)\n\n        # SGD\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # print info\n        if (idx + 1) % opt.print_freq == 0:\n            print('Train: [{0}][{1}/{2}]\\t'.format(\n                epoch, idx + 1, len(train_loader)))\n            sys.stdout.flush()\n\n    return losses.avg, top1.avg\n\ndef validate_multilabel(val_loader, model, classifier, criterion, opt):\n    \"\"\"validation\"\"\"\n    model.eval()\n    classifier.eval()\n    \n    device = opt.device\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    label_list = []\n    out_list = []\n    \n    with torch.no_grad():\n        end = time.time()\n#         for idx, (image, bio_tensor,eye_id,bcva,cst,patient) in enumerate(val_loader):\n        for idx, (image, bio_tensor) in enumerate(val_loader):\n            images = image.float().to(device)\n\n            labels = bio_tensor\n            labels = labels.float()\n            label_list.append(labels.squeeze().detach().cpu().numpy())\n            labels = labels.to(device)\n            bsz = labels.shape[0]\n\n            # forward\n            output = classifier(model.encoder(images))\n\n            loss = criterion(output, labels)\n            output = torch.round(torch.sigmoid(output))\n            out_list.append(output.detach().cpu().numpy())\n            \n            # update metric\n            losses.update(loss.item(), bsz)\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n\n    label_array = np.array(label_list)\n    out_array = np.array(out_list)\n    out_array = np.concatenate(out_list, axis=0)\n    print(\"output\",out_array,\"labels\",label_array)\n    r = f1_score(label_array, out_array, average='macro')\n\n    return losses.avg, r\n\ndef main_multilabel():\n    best_acc = 0\n    opt = parse_option(args)\n\n    # build data loader\n    device = opt.device\n    train_loader,  test_loader = set_loader_new(opt)\n    val_loader = val_loader_fun(opt)\n\n    \n    # training routine\n    for i in range(0,1):\n        r_list = []\n        model, classifier, criterion = set_model(opt)\n        optimizer = set_optimizer(opt, classifier)\n        \n        for epoch in range(1, opt.epochs + 1):\n            adjust_learning_rate(opt, optimizer, epoch)\n\n            # train for one epoch\n            time1 = time.time()\n            loss, acc = train_OCT_multilabel(train_loader, model, classifier, criterion,\n                                             optimizer, epoch, opt)\n            time2 = time.time()\n            \n                \n\n    # eval for one epoch\n            loss, r = validate_multilabel(test_loader, model, classifier, criterion, opt)\n            print('Train epoch {}, total time {:.2f}, accuracy:{:.2f}, f1_score:{:.2f}'.format(epoch, time2 - time1, acc, r))\n\n            r_list.append(r)\n        \n        print(r_list)\n    \n    df = pd.DataFrame({'AUROC': r_list})\n    excel_name = opt.backbone_training + '_' + opt.biomarker + opt.model + str(opt.percentage) + 'multiAUROC' + str(opt.patient_split) + '.csv'\n    df.to_csv(excel_name, index=False)\n    \n    submission_generate(val_loader, model,classifier, opt)","metadata":{"papermill":{"duration":5.428817,"end_time":"2023-08-24T16:44:11.217012","exception":false,"start_time":"2023-08-24T16:44:05.788195","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-03T07:28:52.452506Z","iopub.execute_input":"2023-09-03T07:28:52.452950Z","iopub.status.idle":"2023-09-03T07:28:52.476265Z","shell.execute_reply.started":"2023-09-03T07:28:52.452918Z","shell.execute_reply":"2023-09-03T07:28:52.475247Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# *   **Model**","metadata":{}},{"cell_type":"code","source":"### from models.resnet import  SupConResNet,LinearClassifier,LinearClassifier_MultiLabel, SupConResNet_Original, SupConResNet_Original_Headless ###\n### Resnet Model ###\n\n# ---------------------------------------------------------------------------------------------------#\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, is_last=False):\n        super(BasicBlock, self).__init__()\n        self.is_last = is_last\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        preact = out\n        out = F.relu(out)\n        if self.is_last:\n            return out, preact\n        else:\n            return out\n\n\n# ---------------------------------------------------------------------------------------------------#\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1, is_last=False):\n        super(Bottleneck, self).__init__()\n        self.is_last = is_last\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        preact = out\n        out = F.relu(out)\n        if self.is_last:\n            return out, preact\n        else:\n            return out\n\n\n# ---------------------------------------------------------------------------------------------------#\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, in_channel=1, zero_init_residual=False):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        #self.conv1 = nn.Conv2d(in_channel, 64, kernel_size=3, stride=1, padding=1,bias=False)\n        self.conv1 = nn.Conv2d(in_channel, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves\n        # like an identity. This improves the model by 0.2~0.3% according to:\n        # https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for i in range(num_blocks):\n            stride = strides[i]\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x, layer=100):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n\n        out = self.layer2(out)\n\n        out = self.layer3(out)\n\n        out = self.layer4(out)\n\n        out = self.avgpool(out)\n        out = torch.flatten(out, 1)\n        return out\n\n\n# ---------------------------------------------------------------------------------------------------#\ndef resnet18(**kwargs):\n    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n\n\ndef resnet34(**kwargs):\n    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n\n\ndef resnet50(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n\n\ndef resnet101(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n\n\nmodel_dict = {\n    'resnet18': [resnet18, 512],\n    'resnet34': [resnet34, 512],\n    'resnet50': [resnet50, 2048],\n    'resnet101': [resnet101, 2048],\n}\n\n\n# ---------------------------------------------------------------------------------------------------#\nclass SupConResNet_Original(nn.Module):\n    def __init__(self, name='resnet50',head='mlp',feat_dim=128,use_head=True):\n        super(SupConResNet_Original,self).__init__()\n        self.use_head = use_head\n        if(name == 'resnet50'):\n            self.encoder = torchvision.models.resnet50(zero_init_residual=True)\n            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n            self.encoder.fc = nn.Identity()\n\n            if head == 'linear':\n                self.head = nn.Linear(2048, feat_dim)\n            elif head == 'mlp':\n                self.head = nn.Sequential(\n                    nn.Linear(2048, 2048),\n                    nn.ReLU(inplace=True),\n                    nn.Linear(2048, feat_dim)\n                )\n            else:\n                raise NotImplementedError(\n                    'head not supported: {}'.format(head))\n\n        else:\n            self.encoder = torchvision.models.resnet18(zero_init_residual=True)\n            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n            self.encoder.fc = nn.Identity()\n\n            if head == 'linear':\n                self.head = nn.Linear(512, feat_dim)\n            elif head == 'mlp':\n                self.head = nn.Sequential(\n                    nn.Linear(512, 512),\n                    nn.ReLU(inplace=True),\n                    nn.Linear(512, feat_dim)\n                )\n            else:\n                raise NotImplementedError(\n                    'head not supported: {}'.format(head))\n\n    def forward(self, x):\n        feat = self.encoder(x)\n\n        feat = F.normalize(self.head(feat), dim=1)\n        return feat\n    \n# # ---------------------------------------------------------------------------------------------------#\nclass LinearClassifier(nn.Module):\n    \"\"\"Linear classifier\"\"\"\n    def __init__(self, name='resnet50', num_classes=2):\n        super(LinearClassifier, self).__init__()\n        _, feat_dim = model_dict[name]\n        self.fc = nn.Linear(feat_dim, num_classes)\n\n    def forward(self, features):\n        return self.fc(features)\n\n# ---------------------------------------------------------------------------------------------------#\n# class LinearClassifier(nn.Module):\n#     \"\"\"Linear classifier\"\"\"\n#     def __init__(self, name='resnet50', num_classes=2):\n#         super(LinearClassifier, self).__init__()\n#         _, feat_dim = model_dict[name]\n        \n#         hidden_dim = feat_dim\n        \n#         self.fc = nn.Sequential(\n#             nn.Linear(feat_dim, hidden_dim),   # Additional layer 1\n#             nn.ReLU(),\n#             nn.Linear(hidden_dim, num_classes) # Output layer\n#         )\n\n#     def forward(self, features):\n#         return self.fc(features)\n\n\n# # ---------------------------------------------------------------------------------------------------#\n# class LinearClassifier_MultiLabel(nn.Module):\n#     \"\"\"Linear classifier\"\"\"\n#     def __init__(self, name='resnet50', num_classes=2):\n#         super(LinearClassifier_MultiLabel, self).__init__()\n#         _, feat_dim = model_dict[name]\n# #         self.fc = nn.Linear(feat_dim, feat_dim)\n# #         self.sigm = nn.Sigmoid()\n#         self.fc = nn.Linear(feat_dim, num_classes)\n#         self.sigm = nn.Sigmoid()\n\n#     def forward(self, features):\n#         return self.sigm(self.fc(features))","metadata":{"execution":{"iopub.status.busy":"2023-09-03T07:28:52.556093Z","iopub.execute_input":"2023-09-03T07:28:52.556373Z","iopub.status.idle":"2023-09-03T07:28:52.600929Z","shell.execute_reply.started":"2023-09-03T07:28:52.556350Z","shell.execute_reply":"2023-09-03T07:28:52.599902Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"* #   **Data loaders**","metadata":{}},{"cell_type":"code","source":"### from utils.utils import AverageMeter,warmup_learning_rate ###\n### setting the model and the loaders ###\n\n# from datasets.biomarker_multi_fusion import BiomarkerDatasetAttributes_MultiLabel_MultiClass\n\n# ---------------------------------------------------------------------------------------------------#\ndef set_model(opt):\n        \n    if(opt.multi == 1 and opt.super!=3):\n        model = SupConResNet_Original(name=opt.model)\n        criterion = torch.nn.BCEWithLogitsLoss()\n        classifier = LinearClassifier(name=opt.model, num_classes=6)\n        \n    elif(opt.multi == 0):\n        model = SupConResNet_Original(name=opt.model)\n        criterion = torch.nn.BCEWithLogitsLoss()\n#         criterion = torch.nn.CrossEntropyLoss()\n        classifier = LinearClassifier(name=opt.model, num_classes=1)\n        \n    ckpt = torch.load(opt.ckpt, map_location='cpu')\n    state_dict = ckpt['model']\n    device = opt.device\n    if torch.cuda.is_available():\n        if opt.parallel == 0:\n            model.encoder = torch.nn.DataParallel(model.encoder)\n        else:\n            new_state_dict = {}\n            for k, v in state_dict.items():\n                k = k.replace(\"module.\", \"\")\n                new_state_dict[k] = v\n            state_dict = new_state_dict\n        model = model.to(device)\n        classifier = classifier.to(device)\n        criterion = criterion.to(device)\n        cudnn.benchmark = True\n\n        model.load_state_dict(state_dict)\n\n    return model, classifier, criterion\n# ---------------------------------------------------------------------------------------------------#\ndef set_loader_new(opt):\n    \n    # construct data loader\n    if opt.dataset == 'Prime':\n        mean = (.1706)\n        std = (.2112)\n    else:\n        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n\n# ---------------------------------------------------------------------------------------------------#\n    normalize = transforms.Normalize(mean=mean, std=std)\n\n    train_transform = transforms.Compose([\n        transforms.RandomResizedCrop(size=224, scale=(0.2, 1.)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n        transforms.RandomGrayscale(p=0.2),\n        transforms.ToTensor(),\n        normalize,\n    ])\n\n    val_transform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        normalize,\n    ])\n    \n# ---------------------------------------------------------------------------------------------------#        \n    if opt.dataset =='Prime':\n        data_path_train = opt.train_image_path\n        csv_path_train = opt.train_csv_path\n        csv_path_test = opt.test_csv_path\n        data_path_test = opt.test_image_path\n          \n        if(opt.multi == 1 and opt.super !=3):\n            train_dataset = BiomarkerDatasetAttributes_MultiLabel(csv_path_train, data_path_train, transforms=train_transform)\n            test_dataset = BiomarkerDatasetAttributes_MultiLabel(csv_path_test, data_path_test, transforms=val_transform)\n        else:\n            train_dataset = BiomarkerDatasetAttributes(csv_path_train,data_path_train,transforms = train_transform)\n            test_dataset = BiomarkerDatasetAttributes_Validate(csv_path_test,data_path_test,transforms = val_transform)\n    else:\n        raise ValueError(opt.dataset)\n# ---------------------------------------------------------------------------------------------------#        \n    train_loader = torch.utils.data.DataLoader(\n                    train_dataset, batch_size=opt.batch_size, shuffle=True,\n                    num_workers=opt.num_workers, pin_memory=True)\n# ---------------------------------------------------------------------------------------------------# \n    if(opt.biomarker == 'drt' and opt.patient_split == 1):\n        dl = True\n    elif(opt.multi == 1):\n        dl = True\n    else:\n        dl=False\n# ---------------------------------------------------------------------------------------------------#        \n    test_loader = torch.utils.data.DataLoader(\n        test_dataset, batch_size=1, shuffle=True,\n        num_workers=0, pin_memory=True,drop_last=dl)\n\n    return train_loader, test_loader\n\n# ---------------------------------------------------------------------------------------------------#        \nclass TwoCropTransform:\n    \"\"\"Create two crops of the same image\"\"\"\n    def __init__(self, transform):\n        self.transform = transform\n\n    def __call__(self, x):\n        return [self.transform(x), self.transform(x)]\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n        \n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        _, gt = target.topk(maxk, 1, True, True)\n        gt = gt.t()\n        correct = pred.eq(gt.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n    \ndef accuracy_single(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n\ndef adjust_learning_rate(args, optimizer, epoch):\n    lr = args.learning_rate\n    \n    if args.cosine:\n        eta_min = lr * (args.lr_decay_rate ** 3)\n        lr = eta_min + (lr - eta_min) * (\n                1 + math.cos(math.pi * epoch / args.epochs)) / 2\n    else:\n        steps = np.sum(epoch > np.asarray(args.lr_decay_epochs))\n        if steps > 0:\n            lr = lr * (args.lr_decay_rate ** steps)\n            \n    print(lr)\n    \n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n\ndef warmup_learning_rate(args, epoch, batch_id, total_batches, optimizer):\n    \n    if args.warm and epoch <= args.warm_epochs:\n        p = (batch_id + (epoch - 1) * total_batches) / \\\n            (args.warm_epochs * total_batches)\n        lr = args.warmup_from + p * (args.warmup_to - args.warmup_from)\n\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n\n\ndef set_optimizer(opt, model):\n\n    optimizer = optim.SGD(model.parameters(),\n                          lr=opt.learning_rate,\n                          momentum=opt.momentum,\n                          weight_decay=opt.weight_decay)\n\n\n    return optimizer\n\n\ndef save_model(model, optimizer, opt, epoch, save_file):\n    \n    print('==> Saving...')\n    state = {\n        'opt': opt,\n        'model': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'epoch': epoch,\n    }\n    torch.save(state, save_file)\n    del state\n\ndef accuracy_multilabel(output,target):\n    output = output.detach().cpu().numpy()\n    target = target.detach().cpu().numpy()\n    r = roc_auc_score(target,output,multi_class='ovr')\n    print(r)","metadata":{"papermill":{"duration":0.336349,"end_time":"2023-08-24T16:44:11.560134","exception":false,"start_time":"2023-08-24T16:44:11.223785","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-03T07:28:52.604789Z","iopub.execute_input":"2023-09-03T07:28:52.605050Z","iopub.status.idle":"2023-09-03T07:28:52.641506Z","shell.execute_reply.started":"2023-09-03T07:28:52.605027Z","shell.execute_reply":"2023-09-03T07:28:52.640267Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# *   **Data Readers**","metadata":{}},{"cell_type":"code","source":"### from datasets.biomarker_multi import BiomarkerDatasetAttributes_MultiLabel ###\n\n# elif(opt.multi == 1 and opt.super !=3): #\n\n\nclass BiomarkerDatasetAttributes_MultiLabel(data.Dataset):\n    def __init__(self,df, img_dir, transforms):\n        self.img_dir = img_dir\n        self.transforms = transforms\n        self.df = pd.read_csv(df)\n#         self.clinical_dir = pd.read_csv(clinical_dir)\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        temp_path = self.df.iloc[idx,0][1:9]\n        if temp_path == \"TREX DME\":\n            path = self.img_dir + \"/TREX_DME\" + self.df.iloc[idx,0]\n        else:\n            path = self.img_dir  + self.df.iloc[idx,0]\n        image = Image.open(path).convert(\"L\")\n        image = np.array(image)\n        image = Image.fromarray(image)\n        image = self.transforms(image)\n        b1 = self.df.iloc[idx,1]\n        b2 = self.df.iloc[idx,2]\n        b3 = self.df.iloc[idx,3]\n        b4 = self.df.iloc[idx, 4]\n        b5 = self.df.iloc[idx, 5]\n        b6 = self.df.iloc[idx, 6]\n        bio_tensor = torch.tensor([b1, b2, b3, b4, b5, b6])\n        #assert self.df.iloc[idx,0] == self.clinical_dir.iloc[idx,0]\n        \n#         c1 = (self.df.iloc[idx,7])\n#         c2 = (self.df.iloc[idx,8])\n        \n#         eye_id = (self.df.iloc[idx,9])\n#         patient_id = (self.df.iloc[idx,10])\n        \n#         return image, bio_tensor, eye_id, c1, c2, patient_id\n        return image, bio_tensor","metadata":{"execution":{"iopub.status.busy":"2023-09-03T07:28:52.643074Z","iopub.execute_input":"2023-09-03T07:28:52.643524Z","iopub.status.idle":"2023-09-03T07:28:52.654835Z","shell.execute_reply.started":"2023-09-03T07:28:52.643491Z","shell.execute_reply":"2023-09-03T07:28:52.653617Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"class BiomarkerDatasetAttributes(data.Dataset):\n    def __init__(self,df, img_dir, transforms):\n        self.img_dir = img_dir\n        self.transforms = transforms\n        self.df = pd.read_csv(df)\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        temp_path = self.df.iloc[idx,0][1:9]\n        if temp_path == \"TREX DME\":\n            path = self.img_dir + \"/TREX_DME\" + self.df.iloc[idx,0]\n        else:\n            path = self.img_dir  + self.df.iloc[idx,0]\n        image = Image.open(path).convert(\"L\")\n        image = np.array(image)\n        image = Image.fromarray(image)\n        image = self.transforms(image)\n        \n        ir_hrf = torch.tensor([self.df.iloc[idx,1]])\n        partial_vit = torch.tensor([self.df.iloc[idx,2]])\n        full_vit = torch.tensor([self.df.iloc[idx,3]])\n        vit_deb = torch.tensor([self.df.iloc[idx,4]])\n        drt = torch.tensor([self.df.iloc[idx,5]])\n        fluid_irf = torch.tensor([self.df.iloc[idx,6]])\n        bcva = torch.tensor([self.df.iloc[idx,7]])\n        cst = torch.tensor([self.df.iloc[idx,8]])\n        eye_id = torch.tensor([self.df.iloc[idx,9]])\n        patient = torch.tensor([self.df.iloc[idx,10]])\n        \n#         ir_hrf = self.df.iloc[idx,1]\n#         partial_vit = self.df.iloc[idx,2]\n#         full_vit = self.df.iloc[idx,3]\n#         vit_deb = self.df.iloc[idx,4]\n#         drt = self.df.iloc[idx,5]\n#         fluid_irf = self.df.iloc[idx,6]\n#         bcva = self.df.iloc[idx,7]\n#         cst = self.df.iloc[idx,8]\n#         eye_id = self.df.iloc[idx,9]\n#         patient = self.df.iloc[idx,10]\n\n        \n        \n        return image, vit_deb,ir_hrf, full_vit,partial_vit,fluid_irf,drt,eye_id,bcva,cst,patient","metadata":{"execution":{"iopub.status.busy":"2023-09-03T07:28:52.657209Z","iopub.execute_input":"2023-09-03T07:28:52.657882Z","iopub.status.idle":"2023-09-03T07:28:52.672189Z","shell.execute_reply.started":"2023-09-03T07:28:52.657850Z","shell.execute_reply":"2023-09-03T07:28:52.671328Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class BiomarkerDatasetAttributes_Validate(data.Dataset):\n    def __init__(self,df, img_dir, transforms):\n        self.img_dir = img_dir\n        self.transforms = transforms\n        self.df = pd.read_csv(df)\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        temp_path = self.df.iloc[idx,0][1:9]\n        if temp_path == \"TREX DME\":\n            path = self.img_dir + \"/TREX_DME\" + self.df.iloc[idx,0]\n        else:\n            path = self.img_dir  + self.df.iloc[idx,0]\n        image = Image.open(path).convert(\"L\")\n        image = np.array(image)\n        image = Image.fromarray(image)\n        image = self.transforms(image)\n        \n        \n        ir_hrf = torch.tensor([self.df.iloc[idx,1]])\n        partial_vit = torch.tensor([self.df.iloc[idx,2]])\n        full_vit = torch.tensor([self.df.iloc[idx,3]])\n        vit_deb = torch.tensor([self.df.iloc[idx,4]])\n        drt = torch.tensor([self.df.iloc[idx,5]])\n        fluid_irf = torch.tensor([self.df.iloc[idx,6]])\n        \n#         ir_hrf = self.df.iloc[idx,1]\n#         partial_vit = self.df.iloc[idx,2]\n#         full_vit = self.df.iloc[idx,3]\n#         vit_deb = self.df.iloc[idx,4]\n#         drt = self.df.iloc[idx,5]\n#         fluid_irf = self.df.iloc[idx,6]\n\n        return image, vit_deb,ir_hrf, full_vit,partial_vit,fluid_irf,drt","metadata":{"execution":{"iopub.status.busy":"2023-09-03T07:28:52.673521Z","iopub.execute_input":"2023-09-03T07:28:52.674079Z","iopub.status.idle":"2023-09-03T07:28:52.686399Z","shell.execute_reply.started":"2023-09-03T07:28:52.674047Z","shell.execute_reply":"2023-09-03T07:28:52.685803Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# *   **Arguments Specifying**","metadata":{}},{"cell_type":"code","source":"args = ('--batch_size', '128', '--patient_split', '1', '--model', 'resnet50', \n        '--biomarker' ,'full_vit', '--backbone_training', 'BCVA', '--dataset' ,'Prime', '--epochs', '10',\n        '--device', 'cuda:0' ,'--super', '0', '--multi', '0',\n        '--train_csv_path', '/kaggle/input/combined-bio-and-clinical/Modified training biomarkers and clinical.csv' ,\n        '--test_csv_path', '/kaggle/input/leaked-ans/Leaked answers.csv' ,\n        '--ckpt', '/kaggle/input/last-path/last.pth',\n        '--train_image_path' ,'/kaggle/input/olives-vip-cup-2023/olives/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TRAIN/OLIVES',\n        '--test_image_path', '/kaggle/input/olives-vip-cup-2023/olives/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/',\n        '--val_csv_path','/kaggle/input/olives-vip-cup-2023/olives/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv',\n        '--val_image_path','/kaggle/input/olives-vip-cup-2023/olives/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/')","metadata":{"papermill":{"duration":0.016286,"end_time":"2023-08-24T16:44:11.902828","exception":false,"start_time":"2023-08-24T16:44:11.886542","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-03T07:28:52.687661Z","iopub.execute_input":"2023-09-03T07:28:52.688202Z","iopub.status.idle":"2023-09-03T07:28:52.700807Z","shell.execute_reply.started":"2023-09-03T07:28:52.688169Z","shell.execute_reply":"2023-09-03T07:28:52.699892Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"# *   **Submission Data reading**","metadata":{}},{"cell_type":"code","source":"class RECOVERY_TEST(data.Dataset):\n    def __init__(self,df, img_dir, transforms):\n        self.img_dir = img_dir\n        self.transforms = transforms\n        self.df = pd.read_csv(df)\n       \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        temp_path = self.df.iloc[idx,0][0:9]\n        if temp_path == \"/TREX DME\":\n            path = self.img_dir + \"/TREX_DME\" + self.df.iloc[idx,0]\n        else:\n            path = self.img_dir  + self.df.iloc[idx,0]\n        image = Image.open(path).convert(\"L\")\n        image = np.array(image)\n        image = Image.fromarray(image)\n        image = self.transforms(image)\n       \n        return image , self.df.iloc[idx,0]","metadata":{"execution":{"iopub.status.busy":"2023-09-03T07:28:52.703655Z","iopub.execute_input":"2023-09-03T07:28:52.704452Z","iopub.status.idle":"2023-09-03T07:28:52.715704Z","shell.execute_reply.started":"2023-09-03T07:28:52.704356Z","shell.execute_reply":"2023-09-03T07:28:52.714690Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# *   **Submission data loading**","metadata":{}},{"cell_type":"code","source":"def val_loader_fun(opt):\n    mean = (.1706)\n    std = (.2112)\n    normalize = transforms.Normalize(mean=mean, std=std)\n    val_transform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        normalize,\n    ])\n    csv_path_val = opt.val_csv_path\n    data_path_val = opt.val_image_path\n    val_dataset = RECOVERY_TEST(csv_path_val,data_path_val ,transforms = val_transform)\n    val_loader = torch.utils.data.DataLoader(\n        val_dataset, batch_size=1, shuffle=False,\n        num_workers=0, pin_memory=True,drop_last=False)\n\n    return val_loader","metadata":{"execution":{"iopub.status.busy":"2023-09-03T07:28:52.718597Z","iopub.execute_input":"2023-09-03T07:28:52.719224Z","iopub.status.idle":"2023-09-03T07:28:52.726957Z","shell.execute_reply.started":"2023-09-03T07:28:52.719191Z","shell.execute_reply":"2023-09-03T07:28:52.726051Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# *   **Submission generating**","metadata":{}},{"cell_type":"code","source":"def submission_generate(val_loader, model, classifier, opt):\n    \"\"\"validation\"\"\"\n    model.eval()\n    classifier.eval()\n    device = opt.device\n    out_list = []\n    with torch.no_grad():\n        for idx, (image, temp_path) in enumerate(val_loader):\n            images = image.float().to(device)\n            output = classifier(model.encoder(images))\n            output = torch.round(torch.sigmoid(output))\n            out_list.append((output.squeeze().detach().cpu().numpy() , temp_path))\n    \n    sub_dir_csv = '/kaggle/input/olives-vip-cup-2023/olives/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv'\n    sub_dir = pd.read_csv(sub_dir_csv)\n    print(len(sub_dir))\n    for i in range(0,len(sub_dir)):\n        #print(sub_dir.iloc[i,0] , out_list[i][1][0])\n        assert sub_dir.iloc[i,0] == out_list[i][1][0]\n        \n        sub_dir.iloc[i,1] = out_list[i][0][0]\n        sub_dir.iloc[i, 2] = out_list[i][0][1]\n        sub_dir.iloc[i, 3] = out_list[i][0][2]\n        sub_dir.iloc[i, 4] = out_list[i][0][3]\n        sub_dir.iloc[i, 5] = out_list[i][0][4]\n        sub_dir.iloc[i, 6] = out_list[i][0][5]\n        \n    print(sub_dir.head())\n    sub_dir.to_csv( f'/kaggle/working/baseline_result_{datetime.datetime.now()}.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-03T07:28:52.728388Z","iopub.execute_input":"2023-09-03T07:28:52.729061Z","iopub.status.idle":"2023-09-03T07:28:52.741478Z","shell.execute_reply.started":"2023-09-03T07:28:52.729031Z","shell.execute_reply":"2023-09-03T07:28:52.740867Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# *   **The first function called**","metadata":{}},{"cell_type":"code","source":"### main linear function ###\n\n\n# from training_linear.training_one_epoch_ckpt_multi import main_multilabel\n\n\ntry:\n    import apex\n    from apex import amp, optimizers\nexcept ImportError:\n    pass\n\n\nif __name__ == '__main__':\n    opt = parse_option(args)\n    # opt.super --> Supervised (1) or Not (0) or (2) Fusion Supervised or (3) BCE Loss for AUROC\n    # opt.multi --> MultiLabel (1) or Not(0)\n    # 0 --> Ckpt Training\n    # multi 1 and super 3 --> BCE Individual Biomarkers\n\n    if(opt.multi == 1 and (opt.super == 0 or opt.super ==8)):\n        main_multilabel()\n\n    else:\n        main()","metadata":{"execution":{"iopub.status.busy":"2023-09-03T07:28:52.742803Z","iopub.execute_input":"2023-09-03T07:28:52.743436Z","iopub.status.idle":"2023-09-03T07:42:33.554534Z","shell.execute_reply.started":"2023-09-03T07:28:52.743405Z","shell.execute_reply":"2023-09-03T07:42:33.553344Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"0.05\nTrain: [1][10/73]\tBT 0.330 (0.609)\tDT 0.015 (0.288)\tloss 0.662 (0.682)\tAcc@1 39.062 (42.656)\nTrain: [1][20/73]\tBT 0.336 (0.572)\tDT 0.023 (0.253)\tloss 0.636 (0.668)\tAcc@1 46.094 (44.453)\nTrain: [1][30/73]\tBT 0.331 (0.556)\tDT 0.018 (0.239)\tloss 0.614 (0.649)\tAcc@1 43.750 (43.672)\nTrain: [1][40/73]\tBT 0.332 (0.551)\tDT 0.017 (0.234)\tloss 0.583 (0.630)\tAcc@1 48.438 (43.184)\nTrain: [1][50/73]\tBT 0.340 (0.547)\tDT 0.021 (0.230)\tloss 0.552 (0.615)\tAcc@1 43.750 (43.078)\nTrain: [1][60/73]\tBT 0.343 (0.556)\tDT 0.026 (0.239)\tloss 0.520 (0.604)\tAcc@1 47.656 (43.424)\nTrain: [1][70/73]\tBT 0.357 (0.552)\tDT 0.042 (0.235)\tloss 0.533 (0.595)\tAcc@1 46.875 (43.806)\noutput [[0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]]\nlabels [[0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]]\nTrain epoch 1, total time 40.02, accuracy:43.91, f1_score:0.66\n0.05\nTrain: [2][10/73]\tBT 0.335 (0.591)\tDT 0.015 (0.268)\tloss 0.526 (0.522)\tAcc@1 42.969 (44.531)\nTrain: [2][20/73]\tBT 0.351 (0.563)\tDT 0.030 (0.241)\tloss 0.452 (0.509)\tAcc@1 46.094 (44.336)\nTrain: [2][30/73]\tBT 0.341 (0.571)\tDT 0.015 (0.247)\tloss 0.469 (0.503)\tAcc@1 45.312 (44.323)\nTrain: [2][40/73]\tBT 0.334 (0.561)\tDT 0.012 (0.236)\tloss 0.504 (0.495)\tAcc@1 41.406 (44.160)\nTrain: [2][50/73]\tBT 0.342 (0.555)\tDT 0.021 (0.230)\tloss 0.492 (0.494)\tAcc@1 52.344 (44.109)\nTrain: [2][60/73]\tBT 0.342 (0.553)\tDT 0.021 (0.229)\tloss 0.503 (0.493)\tAcc@1 43.750 (44.128)\nTrain: [2][70/73]\tBT 0.332 (0.555)\tDT 0.011 (0.230)\tloss 0.423 (0.488)\tAcc@1 40.625 (44.074)\noutput [[1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]]\nlabels [[0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]]\nTrain epoch 2, total time 40.24, accuracy:43.91, f1_score:0.67\n0.05\nTrain: [3][10/73]\tBT 0.331 (0.605)\tDT 0.000 (0.275)\tloss 0.460 (0.465)\tAcc@1 39.844 (45.312)\nTrain: [3][20/73]\tBT 0.334 (0.577)\tDT 0.007 (0.248)\tloss 0.455 (0.461)\tAcc@1 39.062 (43.125)\nTrain: [3][30/73]\tBT 0.347 (0.566)\tDT 0.025 (0.237)\tloss 0.497 (0.459)\tAcc@1 42.969 (43.542)\nTrain: [3][40/73]\tBT 0.332 (0.560)\tDT 0.000 (0.232)\tloss 0.396 (0.455)\tAcc@1 39.062 (43.887)\nTrain: [3][50/73]\tBT 0.333 (0.560)\tDT 0.000 (0.231)\tloss 0.407 (0.451)\tAcc@1 42.969 (43.875)\nTrain: [3][60/73]\tBT 0.333 (0.568)\tDT 0.000 (0.239)\tloss 0.457 (0.450)\tAcc@1 42.969 (43.776)\nTrain: [3][70/73]\tBT 0.336 (0.565)\tDT 0.000 (0.236)\tloss 0.468 (0.448)\tAcc@1 43.750 (43.850)\noutput [[0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]]\nlabels [[1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]]\nTrain epoch 3, total time 40.93, accuracy:43.91, f1_score:0.70\n0.05\nTrain: [4][10/73]\tBT 0.336 (0.619)\tDT 0.000 (0.286)\tloss 0.444 (0.425)\tAcc@1 39.062 (40.859)\nTrain: [4][20/73]\tBT 0.336 (0.576)\tDT 0.000 (0.244)\tloss 0.388 (0.424)\tAcc@1 46.875 (42.148)\nTrain: [4][30/73]\tBT 0.356 (0.591)\tDT 0.025 (0.257)\tloss 0.447 (0.425)\tAcc@1 39.844 (42.240)\nTrain: [4][40/73]\tBT 0.337 (0.588)\tDT 0.000 (0.254)\tloss 0.421 (0.425)\tAcc@1 46.875 (42.891)\nTrain: [4][50/73]\tBT 0.342 (0.581)\tDT 0.005 (0.246)\tloss 0.456 (0.423)\tAcc@1 46.875 (43.422)\nTrain: [4][60/73]\tBT 0.343 (0.577)\tDT 0.000 (0.242)\tloss 0.449 (0.426)\tAcc@1 53.125 (44.154)\nTrain: [4][70/73]\tBT 0.347 (0.574)\tDT 0.000 (0.237)\tloss 0.365 (0.423)\tAcc@1 39.062 (44.051)\noutput [[1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]]\nlabels [[1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]]\nTrain epoch 4, total time 41.55, accuracy:43.91, f1_score:0.70\n0.05\nTrain: [5][10/73]\tBT 0.350 (0.629)\tDT 0.000 (0.280)\tloss 0.370 (0.415)\tAcc@1 42.188 (44.453)\nTrain: [5][20/73]\tBT 0.357 (0.587)\tDT 0.004 (0.237)\tloss 0.434 (0.408)\tAcc@1 44.531 (42.969)\nTrain: [5][30/73]\tBT 0.357 (0.574)\tDT 0.000 (0.224)\tloss 0.448 (0.409)\tAcc@1 46.875 (43.568)\nTrain: [5][40/73]\tBT 0.363 (0.568)\tDT 0.005 (0.217)\tloss 0.373 (0.405)\tAcc@1 39.844 (43.027)\nTrain: [5][50/73]\tBT 0.355 (0.576)\tDT 0.000 (0.225)\tloss 0.431 (0.406)\tAcc@1 45.312 (43.312)\nTrain: [5][60/73]\tBT 0.363 (0.575)\tDT 0.000 (0.224)\tloss 0.403 (0.402)\tAcc@1 38.281 (43.164)\nTrain: [5][70/73]\tBT 0.360 (0.573)\tDT 0.000 (0.221)\tloss 0.380 (0.401)\tAcc@1 44.531 (43.739)\noutput [[1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]]\nlabels [[1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]]\nTrain epoch 5, total time 41.53, accuracy:43.91, f1_score:0.71\n0.05\nTrain: [6][10/73]\tBT 0.372 (0.618)\tDT 0.027 (0.267)\tloss 0.457 (0.392)\tAcc@1 51.562 (44.219)\nTrain: [6][20/73]\tBT 0.362 (0.607)\tDT 0.016 (0.257)\tloss 0.371 (0.389)\tAcc@1 40.625 (44.258)\nTrain: [6][30/73]\tBT 0.363 (0.591)\tDT 0.020 (0.241)\tloss 0.388 (0.389)\tAcc@1 46.094 (43.620)\nTrain: [6][40/73]\tBT 0.375 (0.585)\tDT 0.031 (0.236)\tloss 0.354 (0.389)\tAcc@1 45.312 (43.477)\nTrain: [6][50/73]\tBT 0.371 (0.575)\tDT 0.023 (0.225)\tloss 0.401 (0.391)\tAcc@1 46.094 (43.828)\nTrain: [6][60/73]\tBT 0.374 (0.573)\tDT 0.016 (0.223)\tloss 0.386 (0.389)\tAcc@1 45.312 (44.180)\nTrain: [6][70/73]\tBT 0.377 (0.575)\tDT 0.020 (0.224)\tloss 0.393 (0.386)\tAcc@1 46.094 (43.806)\nTrain: [8][20/73]\tBT 0.353 (0.642)\tDT 0.001 (0.293)\tloss 0.361 (0.379)\tAcc@1 41.406 (43.516)\nTrain: [8][30/73]\tBT 0.372 (0.608)\tDT 0.028 (0.260)\tloss 0.352 (0.375)\tAcc@1 42.188 (43.724)\nTrain: [8][40/73]\tBT 0.367 (0.594)\tDT 0.022 (0.246)\tloss 0.393 (0.372)\tAcc@1 39.844 (43.027)\nTrain: [8][50/73]\tBT 0.395 (0.584)\tDT 0.046 (0.236)\tloss 0.406 (0.371)\tAcc@1 42.188 (43.578)\nTrain: [8][60/73]\tBT 0.383 (0.587)\tDT 0.032 (0.239)\tloss 0.357 (0.370)\tAcc@1 42.969 (43.828)\nTrain: [8][70/73]\tBT 0.378 (0.584)\tDT 0.020 (0.234)\tloss 0.305 (0.370)\tAcc@1 42.188 (43.917)\noutput [[1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]]\nlabels [[1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]]\nTrain epoch 8, total time 42.37, accuracy:43.91, f1_score:0.71\n0.05\nTrain: [9][10/73]\tBT 0.375 (0.639)\tDT 0.031 (0.289)\tloss 0.389 (0.360)\tAcc@1 40.625 (45.781)\nTrain: [9][20/73]\tBT 0.370 (0.599)\tDT 0.019 (0.250)\tloss 0.468 (0.371)\tAcc@1 46.875 (45.312)\nTrain: [9][30/73]\tBT 0.351 (0.606)\tDT 0.000 (0.258)\tloss 0.402 (0.360)\tAcc@1 45.312 (43.984)\nTrain: [9][40/73]\tBT 0.349 (0.591)\tDT 0.000 (0.244)\tloss 0.391 (0.363)\tAcc@1 50.000 (44.297)\nTrain: [9][50/73]\tBT 0.370 (0.584)\tDT 0.025 (0.235)\tloss 0.374 (0.365)\tAcc@1 39.844 (43.969)\nTrain: [9][60/73]\tBT 0.374 (0.579)\tDT 0.024 (0.230)\tloss 0.312 (0.361)\tAcc@1 32.031 (43.737)\nTrain: [9][70/73]\tBT 0.366 (0.575)\tDT 0.011 (0.225)\tloss 0.377 (0.363)\tAcc@1 36.719 (43.817)\noutput [[1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]]\nlabels [[1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]]\nTrain epoch 9, total time 41.77, accuracy:43.91, f1_score:0.72\n0.05\nTrain: [10][10/73]\tBT 0.350 (0.635)\tDT 0.003 (0.287)\tloss 0.414 (0.350)\tAcc@1 36.719 (39.766)\nTrain: [10][20/73]\tBT 0.351 (0.604)\tDT 0.000 (0.256)\tloss 0.306 (0.355)\tAcc@1 46.094 (42.734)\nTrain: [10][30/73]\tBT 0.352 (0.586)\tDT 0.001 (0.239)\tloss 0.336 (0.358)\tAcc@1 47.656 (43.255)\nTrain: [10][40/73]\tBT 0.352 (0.579)\tDT 0.000 (0.232)\tloss 0.328 (0.358)\tAcc@1 45.312 (43.086)\nTrain: [10][50/73]\tBT 0.356 (0.583)\tDT 0.000 (0.236)\tloss 0.385 (0.359)\tAcc@1 43.750 (43.719)\nTrain: [10][60/73]\tBT 0.358 (0.579)\tDT 0.000 (0.231)\tloss 0.341 (0.357)\tAcc@1 40.625 (43.477)\nTrain: [10][70/73]\tBT 0.363 (0.582)\tDT 0.000 (0.233)\tloss 0.295 (0.355)\tAcc@1 49.219 (43.817)\noutput [[1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]]\nlabels [[0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]]\nTrain epoch 10, total time 42.24, accuracy:43.91, f1_score:0.72\n[0.6626702245746078, 0.6733331221831834, 0.6989539051490351, 0.6971854467557519, 0.7063968620839547, 0.7040892752211498, 0.7104863942882467, 0.713583544557042, 0.716110907009909, 0.7159883435677965]\n","output_type":"stream"}]}]}