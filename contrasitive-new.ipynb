{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### Installing tensorboard_logger\n\n!pip install tensorboard_logger","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Importing Libraries\n\nimport numpy as np\nimport pandas as pd \n\nimport os\nimport time\nimport sys\nimport argparse\nimport math\nimport tensorboard_logger as tb_logger\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.models as models\nfrom torchvision import transforms, datasets\n\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom scipy.sparse import csr_matrix\nfrom PIL import Image\nfrom __future__ import print_function","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* # **Arguments**","metadata":{}},{"cell_type":"code","source":"### from config.config_supcon import parse_option\n\n# ------------------------------------------------Model Name-----------------------------------------#\ndef parse_option(args):\n    parser = argparse.ArgumentParser('argument for training')\n\n    parser.add_argument('--print_freq', type=int, default=10,\n                        help='print frequency')\n    parser.add_argument('--save_freq', type=int, default=50,\n                        help='save frequency')\n    parser.add_argument('--batch_size', type=int, default=128,\n                        help='batch_size')\n    parser.add_argument('--num_workers', type=int, default=2,\n                        help='num of workers to use')\n    parser.add_argument('--epochs', type=int, default=100,\n                        help='number of training epochs')\n    parser.add_argument('--device', type=str, default='cuda:0')\n    \n    # optimization\n    parser.add_argument('--learning_rate', type=float, default=0.05,\n                        help='learning rate')\n    parser.add_argument('--patient_lambda', type=float, default=1,\n                        help='learning rate')\n    parser.add_argument('--cluster_lambda', type=float, default=1,\n                        help='learning rate')\n    parser.add_argument('--lr_decay_epochs', type=str, default='100',\n                        help='where to decay lr, can be a list')\n    parser.add_argument('--lr_decay_rate', type=float, default=0.1,\n                        help='decay rate for learning rate')\n    parser.add_argument('--weight_decay', type=float, default=1e-4,\n                        help='weight decay')\n    parser.add_argument('--momentum', type=float, default=0.9,\n                        help='momentum')\n    parser.add_argument('--train_csv_path', type=str, default='train data csv')\n    parser.add_argument('--test_csv_path', type=str, default='test data csv')\n    parser.add_argument('--train_image_path', type=str, default='train data csv')\n    parser.add_argument('--test_image_path', type=str, default='test data csv')\n    parser.add_argument('--results_dir_contrastive', type=str, default='/home/kiran/Desktop/Dev/SupCon_OCT_Clinical/results.txt')\n    parser.add_argument('--percentage', type=int, default=10,\n                        help='momentum')\n    parser.add_argument('--discrete_level', type=int, default=10,\n                        help='discretization Level')\n    parser.add_argument('--parallel', type=int, default=1, help='data parallel')\n    \n    # model dataset\n    parser.add_argument('--model', type=str, default='resnet50')\n    parser.add_argument('--dataset', type=str, default='TREX_DME',\n                        choices=[ 'OCT', 'OCT_Cluster', 'Prime', 'PrimeBio',\n                                 'Recovery_Compressed',\n                                 'Prime_Comb_Bio', 'CombinedBio', 'CombinedBio_Modfied', 'Patient_Split_2_Prime_TREX',\n                                 'Patient_Split_3_Prime_TREX', 'Alpha',\n                                 'Prime_Compressed', 'Prime_TREX_DME_Fixed', 'Prime_TREX_Alpha',\n                                 'Prime_TREX_DME_Discrete',\n                                 'Recovery', 'TREX_DME'], help='dataset')\n    parser.add_argument('--mean', type=str, help='mean of dataset in path in form of str tuple')\n    parser.add_argument('--std', type=str, help='std of dataset in path in form of str tuple')\n    parser.add_argument('--data_folder', type=str, default=None, help='path to custom dataset')\n    parser.add_argument('--size', type=int, default=128, help='parameter for RandomResizedCrop')\n\n    # method\n    parser.add_argument('--num_methods', type=int, default=0,\n                        help='choose method')\n    parser.add_argument('--method1', type=str, default='n',\n                        help='choose method')\n    parser.add_argument('--method2', type=str, default='n',\n                        help='choose method')\n    parser.add_argument('--method3', type=str, default='n',\n                        help='choose method')\n    parser.add_argument('--method4', type=str, default='n',\n                        help='choose method')\n    parser.add_argument('--method5', type=str, default='n',\n                        help='choose method')\n    parser.add_argument('--alpha', type=float, default=1,\n                        help='choose method')\n    parser.add_argument('--gradcon_labels', type=str, default='',\n                        help='choose method')\n    parser.add_argument('--patient_split', type=int, default=1,\n                        help='choose method')\n    parser.add_argument('--quantized', type=int, default=0,\n                        help='choose method')\n\n    # temperature\n    parser.add_argument('--temp', type=float, default=0.07,\n                        help='temperature for loss function')\n\n    # other setting\n    parser.add_argument('--cosine', action='store_true',\n                        help='using cosine annealing')\n    parser.add_argument('--syncBN', action='store_true',\n                        help='using synchronized batch normalization')\n    parser.add_argument('--warm', action='store_true',\n                        help='warm-up for large batch training')\n    parser.add_argument('--trial', type=str, default='0',\n                        help='id for recording multiple runs')\n\n    opt = parser.parse_args(args)\n    \n# ------------------------Check if dataset is path that passed required arguments----------------------#  \n    if opt.dataset == 'path':\n        assert opt.data_folder is not None \\\n               and opt.mean is not None \\\n               and opt.std is not None\n\n# ---------------------------Set the path according to the environment--------------------------------#          \n    if opt.data_folder is None:\n        opt.data_folder = './datasets/'\n    opt.model_path = './save/SupCon/{}_models'.format(opt.dataset)\n    opt.tb_path = './save/SupCon/{}_tensorboard'.format(opt.dataset)\n\n    iterations = opt.lr_decay_epochs.split(',')\n    opt.lr_decay_epochs = list([])\n    for it in iterations:\n        opt.lr_decay_epochs.append(int(it))\n        \n# ------------------------------------------------Model Name-----------------------------------------#\n    opt.model_name = '{}_{}_{}_{}_{}_{}_{}_{}_{}_lr_{}_{}_decay_{}_bsz_{}_temp_{}_trial_{}_{}_{}'. \\\n        format(opt.method1, opt.method2, opt.method3, opt.method4, opt.method5, opt.alpha, opt.patient_split,opt.discrete_level,\n               opt.dataset, opt.model, opt.learning_rate,\n               opt.weight_decay, opt.batch_size, opt.temp, opt.trial, opt.gradcon_labels, opt.quantized)\n\n    if opt.cosine:\n        opt.model_name = '{}_cosine'.format(opt.model_name)\n        \n# -------------------------------------------Storing TensorBoard logs--------------------------------#\n    opt.tb_folder = os.path.join(opt.tb_path, opt.model_name)\n    if not os.path.isdir(opt.tb_folder):\n        os.makedirs(opt.tb_folder)\n        \n# -------------------------------------------Saving model-related files------------------------------#\n    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n    if not os.path.isdir(opt.save_folder):\n        os.makedirs(opt.save_folder)\n\n    return opt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* # **Data loader**","metadata":{}},{"cell_type":"code","source":"## from utils.utils_supcon import set_loader,set_model_contrast\n\n# from datasets.prime_trex_combined import CombinedDataset\n\n\ntry:\n    import apex\n    from apex import amp, optimizers\nexcept ImportError:\n    pass\n\n# ---------------------------------Configuring contrastive model---------------------------------------#\n\ndef set_model_contrast(opt):\n\n    model = SupConResNet_Original(name=opt.model)\n    criterion = SupConLoss(temperature=opt.temp,device=opt.device)\n    device = opt.device\n    \n    # enable synchronized Batch Normalization\n    if opt.syncBN:\n        model = apex.parallel.convert_syncbn_model(model)\n\n    if torch.cuda.is_available():\n        if opt.parallel == 1:\n            model = torch.nn.DataParallel(model)\n            model = model.cuda()\n            criterion = criterion.cuda()\n        else:\n            model = model.to(device)\n            criterion = criterion.to(device)\n        cudnn.benchmark = True\n\n    return model, criterion\n\n# --------------------------------------Set Loader configurations----------------------------------#\n\ndef set_loader(opt):\n    if opt.dataset == 'Prime_TREX_DME_Fixed':\n        mean = (.1706)\n        std = (.2112)  \n    else:\n        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n\n# ------------------------------------------------Model Name-----------------------------------------#\n    \n    normalize = transforms.Normalize(mean=mean, std=std)\n    \n    train_transform = transforms.Compose([\n        transforms.RandomResizedCrop(size=224, scale=(0.2, 1.)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n        transforms.RandomGrayscale(p=0.2),\n        transforms.ToTensor(),\n        normalize,\n    ])\n\n# -------------------------------------------Assign the path-------------------------------------#\n    if opt.dataset == 'Prime_TREX_DME_Fixed':\n        #csv_path_train = './final_csvs_' + str(opt.patient_split) +'/datasets_combined/prime_trex_compressed.csv'\n        csv_path_train = '/kaggle/input/supcon-oct-clinical-master/SupCon_OCT_Clinical-master/final_csvs_1/datasets_combined/prime_trex_compressed.csv'\n        data_path_train = opt.train_image_path\n        train_dataset = CombinedDataset(csv_path_train, data_path_train, transforms=TwoCropTransform(train_transform))\n    \n    else:\n        raise ValueError(opt.dataset)\n    train_sampler = None\n    \n# --------------------------------Load data set to the train_loader--------------------------------#\n    train_loader = torch.utils.data.DataLoader(\n                    train_dataset, batch_size=opt.batch_size, shuffle=True,\n                    num_workers=opt.num_workers, pin_memory=True, sampler=train_sampler,drop_last=True)\n\n    return train_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* # **Utils**","metadata":{}},{"cell_type":"code","source":"### from utils.utils import set_optimizer, adjust_learning_rate,save_model\n\n# --------------------------Create two crops of the same image------------------------------#\nclass TwoCropTransform:\n\n    def __init__(self, transform):\n        self.transform = transform\n\n    def __call__(self, x):\n        return [self.transform(x), self.transform(x)]\n\n# ----------------------Computes and stores the average and current value----------------------#\nclass AverageMeter(object):\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n# ---------------------------calculate the accuracy of model predictions-------------------------#\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n# -----------------------------------Adjust the learning rate-----------------------------------#\ndef adjust_learning_rate(args, optimizer, epoch):\n    \n    lr = args.learning_rate\n    if args.cosine:\n        eta_min = lr * (args.lr_decay_rate ** 3)\n        lr = eta_min + (lr - eta_min) * (\n                1 + math.cos(math.pi * epoch / args.epochs)) / 2\n    else:\n        steps = np.sum(epoch > np.asarray(args.lr_decay_epochs))\n        if steps > 0:\n            lr = lr * (args.lr_decay_rate ** steps)\n            \n    print(lr)\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n# -----------------------------------Warm up the learning rate-----------------------------------#\ndef warmup_learning_rate(args, epoch, batch_id, total_batches, optimizer):\n    if args.warm and epoch <= args.warm_epochs:\n        p = (batch_id + (epoch - 1) * total_batches) / \\\n            (args.warm_epochs * total_batches)\n        lr = args.warmup_from + p * (args.warmup_to - args.warmup_from)\n\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n\n# --------------------------------------Optimizer initializing--------------------------------------#\ndef set_optimizer(opt, model):\n    \n    optimizer = optim.SGD(model.parameters(),\n                          lr=opt.learning_rate,\n                          momentum=opt.momentum,\n                          weight_decay=opt.weight_decay)\n    \n    return optimizer\n\n# ---------------------------------------------Saving the Model-------------------------------------#\ndef save_model(model, optimizer, opt, epoch, save_file):\n    \n    print('==> Saving...')\n    state = {\n        'opt': opt,\n        'model': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'epoch': epoch,\n    }\n    torch.save(state, save_file)\n    del state\n    \n# --------------------------------Load data set to the train_loader--------------------------------#\ndef accuracy_multilabel(output,target):\n    \n    output = output.detach().cpu().numpy()\n    target = target.detach().cpu().numpy()\n    r = roc_auc_score(target,output,multi_class='ovr')\n    print(r)\n    \n# ------------------------------------------------------------------------------------------------#    \n# def set_model_student_teacher(opt):\n\n#     if(opt.multi == 0):\n#         model_student = SupConResNet_Original_Headless(name=opt.model,use_head=False)\n#         model = SupConResNet_Original_Headless(name=opt.model,use_head=False)\n#         classifier = LinearClassifier(name=opt.model, num_classes=2)\n#         model_teacher = nn.Sequential(model,classifier)\n#         model_student = nn.Sequential(model_student,classifier)\n        \n#     criterion = torch.nn.CrossEntropyLoss()\n#     ckpt = torch.load(opt.ckpt, map_location='cpu')\n#     state_dict = ckpt['model']\n#     device = opt.device\n    \n#     if torch.cuda.is_available():\n#         if opt.parallel == 0:\n#             model.encoder = torch.nn.DataParallel(model.encoder)\n#         else:\n#             new_state_dict = {}\n#             for k, v in state_dict.items():\n#                 k = k.replace(\"module.\", \"\")\n#                 k = '0.encoder.' + k[2:]\n#                 if(k=='0.encoder.fc.weight'):\n#                     k = '1.fc.weight'\n#                 if (k == '0.encoder.fc.bias'):\n#                     k = '1.fc.bias'\n#                 #k = k.replace(\"encoder.\", \"\")\n#                 new_state_dict[k] = v\n#             state_dict = new_state_dict\n#         model_teacher = model_teacher.to(device)\n#         model_student = model_student.to(device)\n#         criterion = criterion.to(device)\n#         cudnn.benchmark = True\n\n#         model_teacher.load_state_dict(state_dict)\n\n#     return model_teacher, model_student, criterion","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* # **Training**","metadata":{}},{"cell_type":"code","source":"### from training_supcon.training_one_epoch_prime_trex_combined import train_Combined\n\n\n# -------------------------------------One epoch training--------------------------------------#\ndef train_Combined(train_loader, model, criterion, optimizer, epoch, opt):\n    model.train()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    device = opt.device\n    end = time.time()\n    \n    for idx, (images, bcva,cst,eye_id,patient) in enumerate(train_loader):\n        data_time.update(time.time() - end)\n\n        images = torch.cat([images[0], images[1]], dim=0)\n\n        if torch.cuda.is_available():\n            images = images.to(device)\n\n        bsz = bcva.shape[0]\n\n        # warm-up learning rate\n        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n\n        # compute loss\n        features = model(images)\n        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n\n# -------------------------------------Label initializing--------------------------------------#\n        ### Method 1\n        if opt.method1 == 'patient':\n            labels1 = patient.cuda()\n        elif opt.method1 == 'bcva':\n            labels1 = bcva.cuda()\n        elif opt.method1 == 'cst':\n            labels1 = cst.cuda()\n\n        elif opt.method1 == 'eye_id':\n            labels1 = eye_id.cuda()\n        else:\n            labels1 = 'Null'\n            \n        \n        ### Method 2\n        if opt.method2 == 'patient':\n            labels2 = patient.cuda()\n        elif opt.method2 == 'bcva':\n            labels2 = bcva.cuda()\n        elif opt.method2 == 'cst':\n            labels2 = cst.cuda()\n        elif opt.method2 == 'eye_id':\n            labels2 = eye_id.cuda()\n        else:\n            labels2 = 'Null'\n            \n            \n        ### Method 3\n        if opt.method3 == 'patient':\n            labels3 = patient.cuda()\n        elif opt.method3 == 'bcva':\n            labels3 = bcva.cuda()\n        elif opt.method3 == 'cst':\n            labels3 = cst.cuda()\n        elif opt.method3 == 'eye_id':\n            labels3 = eye_id.cuda()\n        else:\n            labels3 = 'Null'\n            \n            \n        ### Method 4\n        if opt.method4 == 'patient':\n            labels4 = patient.cuda()\n        elif opt.method4 == 'bcva':\n            labels4 = bcva.cuda()\n        elif opt.method4 == 'cst':\n            labels4 = cst.cuda()\n        elif opt.method4 == 'eye_id':\n            labels4 = eye_id.cuda()\n        else:\n            labels4 = 'Null'\n            \n            \n        ### Method 5\n        if opt.method5 == 'patient':\n            labels5 = patient.cuda()\n        elif opt.method5 == 'bcva':\n            labels5 = bcva.cuda()\n        elif opt.method5 == 'cst':\n            labels5 = cst.cuda()\n        elif opt.method5 == 'eye_id':\n            labels5 = eye_id.cuda()\n        else:\n            labels5 = 'Null'\n\n# -------------------------------------Loss criterion selecting--------------------------------------#       \n        if(opt.num_methods == 0):\n            loss = criterion(features)\n        elif(opt.num_methods==1):\n            if (opt.method1 == 'HCL'):\n                loss = simclr_loss_func_hard(features, f1, f2)\n            else:\n                loss= criterion(features,labels1)\n        elif(opt.num_methods == 2):\n            if(opt.method2 == 'SuperClass'):\n                criterion = SupConLoss_SuperClassDistance(temperature=.07)\n                loss = criterion(features,super_labels = labels1)\n            elif(opt.method2 == 'SuperClass_Combined'):\n                criterion2 = SupConLoss_SuperClassDistance(temperature=.07)\n                loss = criterion(features) +  criterion2(features,super_labels = labels1)\n            else:\n                loss = criterion(features,labels1) + criterion(features,labels2)\n        elif(opt.num_methods == 3):\n            loss = criterion(features,labels1) + criterion(features,labels2) + criterion(features,labels3)\n        elif (opt.num_methods == 4):\n            loss = criterion(features, labels1) + criterion(features, labels2) + criterion(features, labels3) + criterion(features,labels4)\n        elif (opt.num_methods == 5):\n            loss = criterion(features, labels1) + criterion(features, labels2) + criterion(features, labels3) + criterion(features,labels4) + criterion(features,labels5)\n        else:\n            loss = 'Null'\n            \n\n# -------------------------------------Loss,Optimizer updating--------------------------------------#\n        # update metric\n        losses.update(loss.item(), bsz)\n\n        # SGD\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n# -------------------------------------------Print info----------------------------------------------#\n        if (idx + 1) % opt.print_freq == 0:\n            print('Train: [{0}][{1}/{2}]\\t'\n                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n                  'loss {loss.val:.3f} ({loss.avg:.3f})'.format(\n                   epoch, idx + 1, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses))\n            sys.stdout.flush()\n\n    return losses.avg\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* # **Data reading**","metadata":{}},{"cell_type":"code","source":"# from datasets.prime_trex_combined import CombinedDataset\n\n# -------------------------------------One epoch training--------------------------------------#\nclass CombinedDataset(data.Dataset):\n    def __init__(self,df, img_dir, transforms):\n        self.img_dir = img_dir\n        self.transforms = transforms\n        self.df = pd.read_csv(df)\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        \n        temp_path = self.df.iloc[idx,0][0:9]\n        if temp_path == \"/TREX DME\":\n            path = self.img_dir + \"/TREX_DME\" + self.df.iloc[idx,0]\n        else:\n            path = self.img_dir  + self.df.iloc[idx,0]\n            \n        image = Image.open(path).convert(\"L\")\n        image = np.array(image)\n        image = Image.fromarray(image)\n        image = self.transforms(image)\n\n        bcva=self.df.iloc[idx,1]\n        cst = self.df.iloc[idx, 2]\n        eye = self.df.iloc[idx, 3]\n        patient = self.df.iloc[idx, 4]\n\n\n        return image, bcva,cst,eye,patient","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* #  **Model**","metadata":{}},{"cell_type":"code","source":"# from models.resnet import SupConResNet, SupConResNet_Original\n\n\n# -------------------Fundamental building block within a neural network architecture--------------------#\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, is_last=False):\n        super(BasicBlock, self).__init__()\n        self.is_last = is_last\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        preact = out\n        out = F.relu(out)\n        if self.is_last:\n            return out, preact\n        else:\n            return out\n\n# -------------------------Building block for deep convolutional neural networks-----------------------#\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1, is_last=False):\n        super(Bottleneck, self).__init__()\n        self.is_last = is_last\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        preact = out\n        out = F.relu(out)\n        if self.is_last:\n            return out, preact\n        else:\n            return out\n\n# ---------------------------------Resnet model initializing-----------------------------------#\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, in_channel=1, zero_init_residual=False):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        #self.conv1 = nn.Conv2d(in_channel, 64, kernel_size=3, stride=1, padding=1,bias=False)\n        self.conv1 = nn.Conv2d(in_channel, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves\n        # like an identity. This improves the model by 0.2~0.3% according to:\n        # https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for i in range(num_blocks):\n            stride = strides[i]\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x, layer=100):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n\n        out = self.layer2(out)\n\n        out = self.layer3(out)\n\n        out = self.layer4(out)\n\n        out = self.avgpool(out)\n        out = torch.flatten(out, 1)\n        return out\n\n# -------------------------------Resnet model information--------------------------------#\ndef resnet18(**kwargs):\n    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n\n\ndef resnet34(**kwargs):\n    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n\n\ndef resnet50(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n\n\ndef resnet101(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n\n\nmodel_dict = {\n    'resnet18': [resnet18, 512],\n    'resnet34': [resnet34, 512],\n    'resnet50': [resnet50, 2048],\n    'resnet101': [resnet101, 2048],\n}\n\n# --------------------------------------Used Resnet Model-------------------------------------#\nclass SupConResNet_Original(nn.Module):\n    def __init__(self, name='resnet50',head='mlp',feat_dim=128,use_head=True):\n        super(SupConResNet_Original,self).__init__()\n        self.use_head = use_head\n        if(name == 'resnet50'):\n            self.encoder = torchvision.models.resnet50(zero_init_residual=True)\n            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n            self.encoder.fc = nn.Identity()\n\n            if head == 'linear':\n                self.head = nn.Linear(2048, feat_dim)\n            elif head == 'mlp':\n                self.head = nn.Sequential(\n                    nn.Linear(2048, 2048),\n                    nn.ReLU(inplace=True),\n                    nn.Linear(2048, feat_dim)\n                )\n            else:\n                raise NotImplementedError(\n                    'head not supported: {}'.format(head))\n\n        else:\n            self.encoder = torchvision.models.resnet18(zero_init_residual=True)\n            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n            self.encoder.fc = nn.Identity()\n\n            if head == 'linear':\n                self.head = nn.Linear(512, feat_dim)\n            elif head == 'mlp':\n                self.head = nn.Sequential(\n                    nn.Linear(512, 512),\n                    nn.ReLU(inplace=True),\n                    nn.Linear(512, feat_dim)\n                )\n            else:\n                raise NotImplementedError(\n                    'head not supported: {}'.format(head))\n\n    def forward(self, x):\n        feat = self.encoder(x)\n\n        feat = F.normalize(self.head(feat), dim=1)\n        return feat\n    \n\n# class LinearBatchNorm(nn.Module):\n#     \"\"\"Implements BatchNorm1d by BatchNorm2d, for SyncBN purpose\"\"\"\n#     def __init__(self, dim, affine=True):\n#         super(LinearBatchNorm, self).__init__()\n#         self.dim = dim\n#         self.bn = nn.BatchNorm2d(dim, affine=affine)\n\n#     def forward(self, x):\n#         x = x.view(-1, self.dim, 1, 1)\n#         x = self.bn(x)\n#         x = x.view(-1, self.dim)\n#         return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* # **Loss**","metadata":{}},{"cell_type":"code","source":"# from loss.loss import SupConLoss\n\nclass SupConLoss(nn.Module):\n    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n    def __init__(self, device='cuda:0',temperature=0.07, contrast_mode='all',\n                 base_temperature=0.07):\n        super(SupConLoss, self).__init__()\n        self.temperature = temperature\n        self.contrast_mode = contrast_mode\n        self.base_temperature = base_temperature\n        self.device = device\n    def forward(self, features, labels=None, mask=None):\n        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n        it degenerates to SimCLR unsupervised loss:\n        https://arxiv.org/pdf/2002.05709.pdf\n        Args:\n            features: hidden vector of shape [bsz, n_views, ...].\n            labels: ground truth of shape [bsz].\n            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n                has the same class as sample i. Can be asymmetric.\n        Returns:\n            A loss scalar.\n        \"\"\"\n        device = self.device\n\n        if len(features.shape) < 3:\n            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n                             'at least 3 dimensions are required')\n        if len(features.shape) > 3:\n            features = features.view(features.shape[0], features.shape[1], -1)\n\n        batch_size = features.shape[0]\n        if labels is not None and mask is not None:\n            raise ValueError('Cannot define both `labels` and `mask`')\n        elif labels is None and mask is None:\n            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n        elif labels is not None:\n            labels = labels.contiguous().view(-1, 1)\n            if labels.shape[0] != batch_size:\n                raise ValueError('Num of labels does not match num of features')\n            mask = torch.eq(labels, labels.T).float().to(device)\n        else:\n            mask = mask.float().to(device)\n\n        contrast_count = features.shape[1]\n        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n        if self.contrast_mode == 'one':\n            anchor_feature = features[:, 0]\n            anchor_count = 1\n        elif self.contrast_mode == 'all':\n            anchor_feature = contrast_feature\n            anchor_count = contrast_count\n        else:\n            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n\n        # compute logits\n        anchor_dot_contrast = torch.div(\n            torch.matmul(anchor_feature, contrast_feature.T),\n            self.temperature)\n\n        # for numerical stability\n        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n        logits = anchor_dot_contrast - logits_max.detach()\n\n        # tile mask\n        mask = mask.repeat(anchor_count, contrast_count)\n        # mask-out self-contrast cases\n        logits_mask = torch.scatter(\n            torch.ones_like(mask),\n            1,\n            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n            0\n        )\n        mask = mask * logits_mask\n\n        # compute log_prob\n        exp_logits = torch.exp(logits) * logits_mask\n        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n\n        # compute mean of log-likelihood over positive\n        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n\n        # loss\n        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n        loss = loss.view(anchor_count, batch_size).mean()\n\n        return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* # **Main**","metadata":{}},{"cell_type":"code","source":"# from training_supcon.training_one_epoch_trex import train_TREX\n\ndef main():\n    opt = parse_option(args)\n\n    # build data loader\n    train_loader = set_loader(opt)\n\n    # build model and criterion\n    model, criterion = set_model_contrast(opt)\n\n    # build optimizer\n    optimizer = set_optimizer(opt, model)\n\n    # tensorboard\n    logger = tb_logger.Logger(logdir=opt.tb_folder, flush_secs=2)\n    # training routine\n    for epoch in range(1, opt.epochs + 1):\n        adjust_learning_rate(opt, optimizer, epoch)\n\n        # train for one epoch\n        time1 = time.time()\n\n        if(opt.dataset == 'Prime_TREX_DME_Fixed'):\n            loss = train_Combined(train_loader, model, criterion, optimizer, epoch, opt)\n        \n        time2 = time.time()\n        print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n\n        # tensorboard logger\n        logger.log_value('loss', loss, epoch)\n        logger.log_value('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n\n        if epoch % opt.save_freq == 0:\n            save_file = os.path.join(\n                opt.save_folder, 'ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n            save_model(model, optimizer, opt, epoch, save_file)\n\n    save_file = os.path.join(\n        opt.save_folder, 'last.pth')\n    save_model(model, optimizer, opt, opt.epochs, save_file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* # **Arguments**","metadata":{}},{"cell_type":"code","source":"args = ('--batch_size', '128', '--patient_split', '1', '--model', 'resnet50','--num_methods', '2',\n        '--method1','bcva','--method2','eye_id','--dataset' ,'Prime_TREX_DME_Fixed', '--epochs', '25','--device' ,'cuda:0',\n        '--train_image_path' ,'/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TRAIN/OLIVES')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Run the code**","metadata":{}},{"cell_type":"code","source":"lets_run_the_code = main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}